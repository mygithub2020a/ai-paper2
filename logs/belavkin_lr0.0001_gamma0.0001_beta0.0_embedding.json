[
    {
        "epoch": 0,
        "train_loss": 4.593257427215576,
        "test_loss": 4.590317249298096,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 1,
        "train_loss": 4.593233108520508,
        "test_loss": 4.590295791625977,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 2,
        "train_loss": 4.593209266662598,
        "test_loss": 4.590274810791016,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 3,
        "train_loss": 4.5931854248046875,
        "test_loss": 4.5902533531188965,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 4,
        "train_loss": 4.593161582946777,
        "test_loss": 4.5902323722839355,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 5,
        "train_loss": 4.593137741088867,
        "test_loss": 4.590211391448975,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 6,
        "train_loss": 4.593114376068115,
        "test_loss": 4.5901899337768555,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 7,
        "train_loss": 4.593090057373047,
        "test_loss": 4.5901689529418945,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 8,
        "train_loss": 4.593066215515137,
        "test_loss": 4.590147495269775,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 9,
        "train_loss": 4.593042373657227,
        "test_loss": 4.5901265144348145,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 10,
        "train_loss": 4.593019008636475,
        "test_loss": 4.5901055335998535,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 11,
        "train_loss": 4.5929951667785645,
        "test_loss": 4.590084075927734,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 12,
        "train_loss": 4.592971324920654,
        "test_loss": 4.590063095092773,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 13,
        "train_loss": 4.592947959899902,
        "test_loss": 4.590041637420654,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 14,
        "train_loss": 4.592923641204834,
        "test_loss": 4.590021133422852,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 15,
        "train_loss": 4.592900276184082,
        "test_loss": 4.590000152587891,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 16,
        "train_loss": 4.59287691116333,
        "test_loss": 4.5899786949157715,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 17,
        "train_loss": 4.592852592468262,
        "test_loss": 4.5899577140808105,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 18,
        "train_loss": 4.59282922744751,
        "test_loss": 4.589936256408691,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 19,
        "train_loss": 4.5928053855896,
        "test_loss": 4.589915752410889,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 20,
        "train_loss": 4.592781066894531,
        "test_loss": 4.589893817901611,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 21,
        "train_loss": 4.592757701873779,
        "test_loss": 4.58987283706665,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 22,
        "train_loss": 4.592734336853027,
        "test_loss": 4.5898518562316895,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 23,
        "train_loss": 4.592710018157959,
        "test_loss": 4.58983039855957,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 24,
        "train_loss": 4.592687129974365,
        "test_loss": 4.589808940887451,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 25,
        "train_loss": 4.592663288116455,
        "test_loss": 4.58978796005249,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 26,
        "train_loss": 4.592638969421387,
        "test_loss": 4.589766502380371,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 27,
        "train_loss": 4.592614650726318,
        "test_loss": 4.58974552154541,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 28,
        "train_loss": 4.592591285705566,
        "test_loss": 4.589724063873291,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 29,
        "train_loss": 4.5925679206848145,
        "test_loss": 4.58970308303833,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 30,
        "train_loss": 4.592544078826904,
        "test_loss": 4.589681625366211,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 31,
        "train_loss": 4.592520236968994,
        "test_loss": 4.589661121368408,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 32,
        "train_loss": 4.592496395111084,
        "test_loss": 4.589640140533447,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 33,
        "train_loss": 4.592472076416016,
        "test_loss": 4.589618682861328,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 34,
        "train_loss": 4.592448711395264,
        "test_loss": 4.589597702026367,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 35,
        "train_loss": 4.592425346374512,
        "test_loss": 4.589576244354248,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 36,
        "train_loss": 4.59240198135376,
        "test_loss": 4.589555740356445,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 37,
        "train_loss": 4.592377662658691,
        "test_loss": 4.589534282684326,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 38,
        "train_loss": 4.592353343963623,
        "test_loss": 4.589512825012207,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 39,
        "train_loss": 4.592329978942871,
        "test_loss": 4.589491844177246,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 40,
        "train_loss": 4.592306613922119,
        "test_loss": 4.589470386505127,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 41,
        "train_loss": 4.592282772064209,
        "test_loss": 4.589449882507324,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 42,
        "train_loss": 4.592258930206299,
        "test_loss": 4.589428424835205,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 43,
        "train_loss": 4.592235088348389,
        "test_loss": 4.589407444000244,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 44,
        "train_loss": 4.5922112464904785,
        "test_loss": 4.589386463165283,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 45,
        "train_loss": 4.592187881469727,
        "test_loss": 4.589364528656006,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 46,
        "train_loss": 4.592163562774658,
        "test_loss": 4.589343547821045,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 47,
        "train_loss": 4.592139720916748,
        "test_loss": 4.589322090148926,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 48,
        "train_loss": 4.592116355895996,
        "test_loss": 4.589300632476807,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 49,
        "train_loss": 4.592092514038086,
        "test_loss": 4.589279651641846,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 50,
        "train_loss": 4.592068195343018,
        "test_loss": 4.589258193969727,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 51,
        "train_loss": 4.592044353485107,
        "test_loss": 4.589237213134766,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 52,
        "train_loss": 4.5920209884643555,
        "test_loss": 4.5892157554626465,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 53,
        "train_loss": 4.5919976234436035,
        "test_loss": 4.589195251464844,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 54,
        "train_loss": 4.591973781585693,
        "test_loss": 4.589174270629883,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 55,
        "train_loss": 4.591950416564941,
        "test_loss": 4.589152812957764,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 56,
        "train_loss": 4.591926097869873,
        "test_loss": 4.589131832122803,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 57,
        "train_loss": 4.591902256011963,
        "test_loss": 4.589110851287842,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 58,
        "train_loss": 4.591878890991211,
        "test_loss": 4.589089393615723,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 59,
        "train_loss": 4.591855525970459,
        "test_loss": 4.589068412780762,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 60,
        "train_loss": 4.591831207275391,
        "test_loss": 4.589046955108643,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 61,
        "train_loss": 4.591807842254639,
        "test_loss": 4.58902645111084,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 62,
        "train_loss": 4.59178352355957,
        "test_loss": 4.589005470275879,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 63,
        "train_loss": 4.591760158538818,
        "test_loss": 4.58898401260376,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 64,
        "train_loss": 4.591736316680908,
        "test_loss": 4.588963031768799,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 65,
        "train_loss": 4.591712951660156,
        "test_loss": 4.588942050933838,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 66,
        "train_loss": 4.591689109802246,
        "test_loss": 4.588920593261719,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 67,
        "train_loss": 4.5916643142700195,
        "test_loss": 4.5888991355896,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 68,
        "train_loss": 4.591640949249268,
        "test_loss": 4.588878154754639,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 69,
        "train_loss": 4.591617107391357,
        "test_loss": 4.5888566970825195,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 70,
        "train_loss": 4.591593265533447,
        "test_loss": 4.588834762573242,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 71,
        "train_loss": 4.591569900512695,
        "test_loss": 4.588813781738281,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 72,
        "train_loss": 4.591546535491943,
        "test_loss": 4.58879280090332,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 73,
        "train_loss": 4.591523170471191,
        "test_loss": 4.588771820068359,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 74,
        "train_loss": 4.591498374938965,
        "test_loss": 4.588750839233398,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 75,
        "train_loss": 4.591475009918213,
        "test_loss": 4.5887298583984375,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 76,
        "train_loss": 4.5914506912231445,
        "test_loss": 4.588708877563477,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 77,
        "train_loss": 4.591427326202393,
        "test_loss": 4.588687419891357,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 78,
        "train_loss": 4.591403961181641,
        "test_loss": 4.588665962219238,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 79,
        "train_loss": 4.591380596160889,
        "test_loss": 4.588644504547119,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 80,
        "train_loss": 4.59135627746582,
        "test_loss": 4.588624000549316,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 81,
        "train_loss": 4.59133243560791,
        "test_loss": 4.5886030197143555,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 82,
        "train_loss": 4.591309070587158,
        "test_loss": 4.5885820388793945,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 83,
        "train_loss": 4.591285228729248,
        "test_loss": 4.588560581207275,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 84,
        "train_loss": 4.591261863708496,
        "test_loss": 4.588539123535156,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 85,
        "train_loss": 4.591238021850586,
        "test_loss": 4.5885186195373535,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 86,
        "train_loss": 4.591214656829834,
        "test_loss": 4.588497161865234,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 87,
        "train_loss": 4.591189384460449,
        "test_loss": 4.588476181030273,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 88,
        "train_loss": 4.591166019439697,
        "test_loss": 4.5884552001953125,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 89,
        "train_loss": 4.591142177581787,
        "test_loss": 4.588433742523193,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 90,
        "train_loss": 4.591118812561035,
        "test_loss": 4.588412761688232,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 91,
        "train_loss": 4.591094493865967,
        "test_loss": 4.5883917808532715,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 92,
        "train_loss": 4.591071128845215,
        "test_loss": 4.588370323181152,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 93,
        "train_loss": 4.5910468101501465,
        "test_loss": 4.588347911834717,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 94,
        "train_loss": 4.5910234451293945,
        "test_loss": 4.588327407836914,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 95,
        "train_loss": 4.591000080108643,
        "test_loss": 4.588306427001953,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 96,
        "train_loss": 4.590976238250732,
        "test_loss": 4.588285446166992,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 97,
        "train_loss": 4.5909528732299805,
        "test_loss": 4.588263988494873,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 98,
        "train_loss": 4.590928554534912,
        "test_loss": 4.588242530822754,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 99,
        "train_loss": 4.590904712677002,
        "test_loss": 4.588221549987793,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 100,
        "train_loss": 4.590880870819092,
        "test_loss": 4.588200569152832,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 101,
        "train_loss": 4.59085750579834,
        "test_loss": 4.588179588317871,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 102,
        "train_loss": 4.590834140777588,
        "test_loss": 4.588158130645752,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 103,
        "train_loss": 4.5908098220825195,
        "test_loss": 4.588137149810791,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 104,
        "train_loss": 4.590786457061768,
        "test_loss": 4.58811616897583,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 105,
        "train_loss": 4.590762615203857,
        "test_loss": 4.588095188140869,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 106,
        "train_loss": 4.590738773345947,
        "test_loss": 4.588074207305908,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 107,
        "train_loss": 4.590714931488037,
        "test_loss": 4.588052749633789,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 108,
        "train_loss": 4.590691089630127,
        "test_loss": 4.588031768798828,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 109,
        "train_loss": 4.590666770935059,
        "test_loss": 4.588010787963867,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 110,
        "train_loss": 4.590643405914307,
        "test_loss": 4.587989330291748,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 111,
        "train_loss": 4.5906195640563965,
        "test_loss": 4.587968349456787,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 112,
        "train_loss": 4.5905961990356445,
        "test_loss": 4.587946891784668,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 113,
        "train_loss": 4.590572357177734,
        "test_loss": 4.587926387786865,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 114,
        "train_loss": 4.590548992156982,
        "test_loss": 4.587904453277588,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 115,
        "train_loss": 4.590524673461914,
        "test_loss": 4.587882995605469,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 116,
        "train_loss": 4.590500354766846,
        "test_loss": 4.587862014770508,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 117,
        "train_loss": 4.590477466583252,
        "test_loss": 4.587841033935547,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 118,
        "train_loss": 4.590453624725342,
        "test_loss": 4.587820053100586,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 119,
        "train_loss": 4.59043025970459,
        "test_loss": 4.587798118591309,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 120,
        "train_loss": 4.59040641784668,
        "test_loss": 4.587777137756348,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 121,
        "train_loss": 4.590382099151611,
        "test_loss": 4.587756156921387,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 122,
        "train_loss": 4.590358734130859,
        "test_loss": 4.587734699249268,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 123,
        "train_loss": 4.590334892272949,
        "test_loss": 4.587713718414307,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 124,
        "train_loss": 4.590311527252197,
        "test_loss": 4.587693214416504,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 125,
        "train_loss": 4.590287685394287,
        "test_loss": 4.587671756744385,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 126,
        "train_loss": 4.590263366699219,
        "test_loss": 4.587650299072266,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 127,
        "train_loss": 4.59023904800415,
        "test_loss": 4.587629318237305,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 128,
        "train_loss": 4.590215682983398,
        "test_loss": 4.587608337402344,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 129,
        "train_loss": 4.5901923179626465,
        "test_loss": 4.587586879730225,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 130,
        "train_loss": 4.590168476104736,
        "test_loss": 4.587565898895264,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 131,
        "train_loss": 4.590145111083984,
        "test_loss": 4.587544918060303,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 132,
        "train_loss": 4.590121269226074,
        "test_loss": 4.587523937225342,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 133,
        "train_loss": 4.590096950531006,
        "test_loss": 4.587502479553223,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 134,
        "train_loss": 4.590073585510254,
        "test_loss": 4.587481498718262,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 135,
        "train_loss": 4.590049743652344,
        "test_loss": 4.587460994720459,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 136,
        "train_loss": 4.590026378631592,
        "test_loss": 4.587439060211182,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 137,
        "train_loss": 4.590002059936523,
        "test_loss": 4.5874176025390625,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 138,
        "train_loss": 4.58997917175293,
        "test_loss": 4.587396621704102,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 139,
        "train_loss": 4.589954853057861,
        "test_loss": 4.587375164031982,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 140,
        "train_loss": 4.589931488037109,
        "test_loss": 4.5873541831970215,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 141,
        "train_loss": 4.589907646179199,
        "test_loss": 4.587332725524902,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 142,
        "train_loss": 4.589883327484131,
        "test_loss": 4.5873122215271,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 143,
        "train_loss": 4.589860439300537,
        "test_loss": 4.587291240692139,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 144,
        "train_loss": 4.589836597442627,
        "test_loss": 4.587269306182861,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 145,
        "train_loss": 4.589812278747559,
        "test_loss": 4.5872483253479,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 146,
        "train_loss": 4.589788436889648,
        "test_loss": 4.587227821350098,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 147,
        "train_loss": 4.589764595031738,
        "test_loss": 4.58720588684082,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 148,
        "train_loss": 4.589741230010986,
        "test_loss": 4.587184906005859,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 149,
        "train_loss": 4.589717388153076,
        "test_loss": 4.58716344833374,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 150,
        "train_loss": 4.589694023132324,
        "test_loss": 4.5871429443359375,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 151,
        "train_loss": 4.589670181274414,
        "test_loss": 4.587121486663818,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 152,
        "train_loss": 4.589645862579346,
        "test_loss": 4.587100982666016,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 153,
        "train_loss": 4.589622497558594,
        "test_loss": 4.587079048156738,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 154,
        "train_loss": 4.589598178863525,
        "test_loss": 4.587058067321777,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 155,
        "train_loss": 4.589574813842773,
        "test_loss": 4.587037086486816,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 156,
        "train_loss": 4.5895514488220215,
        "test_loss": 4.5870161056518555,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 157,
        "train_loss": 4.589527606964111,
        "test_loss": 4.586994647979736,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 158,
        "train_loss": 4.589503765106201,
        "test_loss": 4.586973667144775,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 159,
        "train_loss": 4.589479923248291,
        "test_loss": 4.5869526863098145,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 160,
        "train_loss": 4.589456081390381,
        "test_loss": 4.586931228637695,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 161,
        "train_loss": 4.589432716369629,
        "test_loss": 4.586909770965576,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 162,
        "train_loss": 4.589409351348877,
        "test_loss": 4.586888790130615,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 163,
        "train_loss": 4.589385032653809,
        "test_loss": 4.5868682861328125,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 164,
        "train_loss": 4.589361667633057,
        "test_loss": 4.586845874786377,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 165,
        "train_loss": 4.589337348937988,
        "test_loss": 4.586825370788574,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 166,
        "train_loss": 4.589313507080078,
        "test_loss": 4.586803913116455,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 167,
        "train_loss": 4.589290142059326,
        "test_loss": 4.586782932281494,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 168,
        "train_loss": 4.589266300201416,
        "test_loss": 4.586761951446533,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 169,
        "train_loss": 4.589241981506348,
        "test_loss": 4.586740016937256,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 170,
        "train_loss": 4.589218616485596,
        "test_loss": 4.586718559265137,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 171,
        "train_loss": 4.5891947746276855,
        "test_loss": 4.586698055267334,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 172,
        "train_loss": 4.589170932769775,
        "test_loss": 4.586677551269531,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 173,
        "train_loss": 4.589147567749023,
        "test_loss": 4.586656093597412,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 174,
        "train_loss": 4.589123725891113,
        "test_loss": 4.586634635925293,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 175,
        "train_loss": 4.589100360870361,
        "test_loss": 4.58661413192749,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 176,
        "train_loss": 4.589076519012451,
        "test_loss": 4.586592197418213,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 177,
        "train_loss": 4.589052677154541,
        "test_loss": 4.586571216583252,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 178,
        "train_loss": 4.589028835296631,
        "test_loss": 4.586550235748291,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 179,
        "train_loss": 4.589004993438721,
        "test_loss": 4.58652925491333,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 180,
        "train_loss": 4.588981628417969,
        "test_loss": 4.586507797241211,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 181,
        "train_loss": 4.588957786560059,
        "test_loss": 4.58648681640625,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 182,
        "train_loss": 4.588934421539307,
        "test_loss": 4.586465358734131,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 183,
        "train_loss": 4.58890962600708,
        "test_loss": 4.58644437789917,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 184,
        "train_loss": 4.588886260986328,
        "test_loss": 4.586423397064209,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 185,
        "train_loss": 4.588862419128418,
        "test_loss": 4.586402416229248,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 186,
        "train_loss": 4.588839054107666,
        "test_loss": 4.586380958557129,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 187,
        "train_loss": 4.588814735412598,
        "test_loss": 4.586359977722168,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 188,
        "train_loss": 4.588791370391846,
        "test_loss": 4.586338996887207,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 189,
        "train_loss": 4.5887675285339355,
        "test_loss": 4.586317539215088,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 190,
        "train_loss": 4.588743686676025,
        "test_loss": 4.586296558380127,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 191,
        "train_loss": 4.588719367980957,
        "test_loss": 4.586275100708008,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 192,
        "train_loss": 4.588696479797363,
        "test_loss": 4.586254119873047,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 193,
        "train_loss": 4.588672161102295,
        "test_loss": 4.586233139038086,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 194,
        "train_loss": 4.588648796081543,
        "test_loss": 4.586211681365967,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 195,
        "train_loss": 4.588624954223633,
        "test_loss": 4.586190223693848,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 196,
        "train_loss": 4.588601589202881,
        "test_loss": 4.586169242858887,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 197,
        "train_loss": 4.588577747344971,
        "test_loss": 4.586148262023926,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 198,
        "train_loss": 4.5885539054870605,
        "test_loss": 4.586126804351807,
        "accuracy": 0.013000000268220901
    },
    {
        "epoch": 199,
        "train_loss": 4.588529586791992,
        "test_loss": 4.586105823516846,
        "accuracy": 0.013000000268220901
    }
]